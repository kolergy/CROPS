{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CropsDB V0.2\n",
    "\n",
    "## CRoissance Optimale des Plantes en Sol\n",
    "\n",
    "Colecte des donnees environementales pour unbe croissance optimale des plantes\n",
    "et stockage de ces donnees dans une base de donmnee de type couchDB.\n",
    "\n",
    "la colecte des donnees repose sur l'utilisation d'un ESP32 equipe des capteurs suivants:\n",
    " - Le capteur DHT22 permet la mesure de la temperature ambiante\n",
    "   ainsi que du niveau d'humiditee ambiante\n",
    " - Le capteur CSMS V1.2 permet la mesure de la quantitee d'eau dans le sol.\n",
    "   CSMS: (Capacitive Soil Moisture Sensor)  \n",
    " - Le captteur BMP085 permet la mesure de la pression et de la temperature\n",
    "   (de maniere semblet'il plus precise aue le DHT mais je ne l'ai pas verifie)\n",
    " - Le capteur TSL2561 Permet de mesurer la lumiere recue par les plantes\n",
    "\n",
    "\n",
    "Ce notebook Jupyter permet d'analyser les donnees captees par les differents capteurs et stookees dans la base CouchDB. Il est a notter qu le maximum de donnees disponibles sont stokees et analysees et pas seulement les donees purement relatives aux plantes. C'est important car ceci permet de mieux comprendre d'eventueles dysfonctionement du systeme.\n",
    "\n",
    " \n",
    "Auteur: kolergy{@}gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explications du Code\n",
    "\n",
    "les imports permettent de faire apel aux libraries necessaires pour l'analyse:\n",
    " - couchdb: permet de se coonecter ave la base de donnees du meme nom et de stocker ou lire des donnees.\n",
    " - pandas: est une librairie de traitement des donnees et permet de manipuler aisement de grandes quantitee de donnees.\n",
    " - matplotlib: permet de generer simplement des graphes, a noter que seule la partie pyplot de cette librarie est chargee. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import couchdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section on definit les parametres a modifier par l'utilisateur, ici les parametres de connection a la base de donnee CouchDB. \n",
    "Puisd on procede a la conection a celle-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBUser      = \"DBUsername\"\n",
    "DBPass      = \"DBPassword\"\n",
    "DBAdr       = \"DBAdress\"\n",
    "DBPort      = \"5984\"         # DB Port\n",
    "couchserver = couchdb.Server(\"http://%s:%s@%s:%s/\" % (DBUser, DBPass,DBAdr,DBPort))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permet de lister l'ensemble des bases existantes sur le serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dbname in couchserver:\n",
    "    print(dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la base \"crops\" est presente sur le serveur on s'y connecte grace a la variable db, si celle-ci n'existep pas on la cree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = \"crops\"\n",
    "if dbname in couchserver:\n",
    "    db = couchserver[dbname]\n",
    "else:\n",
    "    db = couchserver.create(dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois connecte a la base de donnees crops on copie l'integralitee de son contenu dans un dataframe de la bibliotheque Pandas que l'on nomme df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = db.view('_all_docs', include_docs=True)\n",
    "data = [row['doc'] for row in rows]\n",
    "df   = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut imprimer les noms de colones pour identifier les parametre interessant, il est possible de lister les types de donnees associes a chaque colones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le programe de l'ESP le marquage temporel ie: l'horodatage est fait par le stockage de la date dans une variable et de l'heure dans une autre pour etre en mesure d'indexer proprement nos donees il est necessaire de combiner ces deux valeurs afin d'avoir un marquer temporel complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Period'] = df.Date.str.cat(df.Hour,sep=\" \")\n",
    "#print(df.Period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ce marquer d'horodatage complet est transforme en objet datetime qui permet aux pandas d'effectuer des operations temporelles.\n",
    "- Ensuite cet horodatage dans la forme adequate est utilise come index de notre dataframe.\n",
    "- Pour le prouver on afiche les dernieres lignes du dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']   = pd.to_datetime(df['Period'])\n",
    "df.index     = df['date']\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La on s'apercoit que les dernieres valeurs ne sont pas les bonnes, en effet on a atribue un nouvel index a la base de donnees, mais celle-ci n'as pas ete triee par raport a celui-ci.\n",
    "- Il faut donc effectuer un tri sur l'index\n",
    "- on peut ensuite verifier que cela a fonctione\n",
    "\n",
    "Ce tri n'est pas necessaire pour permetre la bone generation de graphes mair permet de mieux s'y retrouver quant on veux faire des operations sur la data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(inplace=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On stoke la derniere base en CSV cela permet d'utiliser d'autres outils d'analyse (a eviter pour de tres grosses bases)\n",
    "\n",
    "- puis on regarde si il y as des enregistrementds dans le futur: si il y en a il ne faut pas conclure que le voyage dans le temps est possible mais plustot certains enregistreemts on des information temporelles erronees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"MyData.csv\")\n",
    "\n",
    "now     = pd.Timestamp.now()\n",
    "\n",
    "df[df['date'] > now]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oneDay  = now-pd.Timedelta('1 day')\n",
    "oneWeek = now-pd.Timedelta('7 day')\n",
    "oneyear = now-pd.Timedelta('365 day')\n",
    "\n",
    "df[df['date'] < oneyear]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now     = pd.Timestamp.now()\n",
    "df = df.drop(df[df['date'] > now].index)\n",
    "df = df.drop(df[df['date'] < oneyear].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =  df.Temp.plot(figsize=(15, 10))\n",
    "df.Hum.plot(secondary_y=True, style='g')\n",
    "ax.set_ylabel('Temperature °C')\n",
    "ax.right_ax.set_ylabel('Humiditee %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Timedelta('1 day'))\n",
    "print(pd.Timestamp.now()-pd.Timedelta('1 day'))\n",
    "\n",
    "df[\"2019/04/16\"].date.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =  df[df['date'] > oneWeek].Temp.plot(figsize=(15, 10))\n",
    "df[df['date'] > oneWeek].Hum.plot(secondary_y=True, style='g')\n",
    "ax.set_ylabel('Temperature °C')\n",
    "ax.right_ax.set_ylabel('Humiditee %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =  df[df['date'] > oneDay].Temp.plot(figsize=(15, 10))\n",
    "df[df['date'] > oneDay].Hum.plot(secondary_y=True, style='g')\n",
    "ax.set_ylabel('Temperature °C')\n",
    "ax.right_ax.set_ylabel('Humiditee %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =  df.plot(y=['Water1','Water2'], figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y=['Water1%','Water2%'], figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['date'] > oneDay].plot(y=['Water1%','Water2%'], figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Epoch.plot(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date.plot(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y=['tSet','tWif','tNTP', 'tJso'], figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y=['tt0'], figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.RSSI.plot(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DTim.plot(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.UpTime.plot(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y=['Pin[0]:','Pin[2]:','Pin[12]:','Pin[13]:','Pin[14]:','Pin[15]:','Pin[25]:','Pin[26]:','Pin[27]:'], figsize=(15, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y=['Pin[32]:','Pin[33]:','Pin[36]:','Pin[39]:'], figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
